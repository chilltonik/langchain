{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:14.448667Z",
     "start_time": "2025-07-26T14:03:14.444696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")"
   ],
   "id": "b7f06300b118f027",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:15.353401Z",
     "start_time": "2025-07-26T14:03:14.861637Z"
    }
   },
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id, client_secret=client_secret, user_agent=\"search-tool\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:18.107824Z",
     "start_time": "2025-07-26T14:03:17.986443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Rec(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    comments: list[str]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"LLM-friendly string representation of the recommendation(s)\"\"\"\n",
    "        return f\"Title: {self.title}\\nDescription: {self.description}\\nComments: {'\\n'.join(self.comments)}\""
   ],
   "id": "b6f0ac1c65ccee3e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:35.912845Z",
     "start_time": "2025-07-26T14:03:22.522302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from praw.models import Comment\n",
    "\n",
    "results = reddit.subreddit(\"all\").search(\"best pizza in EUR rome\")\n",
    "recs = []\n",
    "for submission in results:\n",
    "    title = submission.title\n",
    "    description = submission.selftext\n",
    "    comments = []\n",
    "    for comment in submission.comments.list():\n",
    "        if isinstance(comment, Comment) and comment.ups >= 20:\n",
    "            author = comment.author.name if comment.author else \"unknown\"\n",
    "            comments.append(f\"{author} (upvotes: {comment.ups}) : {comment.body}\")\n",
    "    comments = comments[:3]\n",
    "\n",
    "    if len(comments) == 3:\n",
    "        print(title)\n",
    "        recs.append(Rec(title=title, description=description, comments=comments))\n",
    "    if len(recs) == 3:\n",
    "        break"
   ],
   "id": "78f1b3fcdd252c4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pizza chef who made this pizza won best pizza in the world at the World Pizza Awards in Rome\n",
      "Since pizza is an American food, I'm willing to bet the best pizza is in America.\n",
      "Visited Rome and had one of the best pizzas of my life\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:32.073783Z",
     "start_time": "2025-07-21T06:02:32.066475Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"\\n===\\n\".join([str(rec) for rec in recs]))",
   "id": "21a5a23e50e75484",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The pizza chef who made this pizza won best pizza in the world at the World Pizza Awards in Rome\n",
      "Description: \n",
      "Comments: bronwynnin (upvotes: 896) : What’re your thoughts on it after eating? Doesn’t look the prettiest but I can imagine it tastes pretty good.\n",
      "skepticalbob (upvotes: 216) : I’m guessing this is Tony Gemignani‘a [Tony’s Pizzaria Neapolitano in San Fransisco](https://yelp.to/g3A23KA0rh). Tony was the first non-Italian to win the Neapolitqn contest jn Italy. He beat out over 2000 entrants. Tony’s makes different styles of pizza that most on aren’t Neapolitan style. I’m betting they were out of Neapolitan and he threw a basil leaf on his New Yorker. This pizza was made with an oven designed for maximum volume and isn’t some handcrafted wonder. The bread and ingredient quality are probably pretty good though.\n",
      "\n",
      "Am I right?\n",
      "\n",
      "Edit: Tony also wrote The Pizza Bible, which is a solid book with many different styles of pizzas and good for someone looking for consistent quality cold-fermented pizza as a beginner.\n",
      "clangan524 (upvotes: 38) : Do the World Pizza Awards need judges? Asking for me.\n",
      "===\n",
      "Title: Since pizza is an American food, I'm willing to bet the best pizza is in America.\n",
      "Description: \n",
      "Comments: unknown (upvotes: 1930) : Hahaha bunch of Americans claiming pizza is from the US and then this one dude like \"sweden has the best pizza\" stay strong kid 💪\n",
      "BoglisMobileAcc (upvotes: 299) : Wild take by the dude saying he was in italy for three weeks as a vegetarian and therefore only ate pizza? What..? Theres plenty of vegetarian options in italian cuisine. I’d argue italian food is one of the most vegetarian friendly cuisines in Europe.\n",
      "unknown (upvotes: 490) : the funniest comment was the dude claiming \"italians doing the best they could with what they had\" meaning he couldn't ask for topping such as salami or whatever cause they didn't have any = total bullshit\n",
      "\n",
      "the rest is really subjective. If americans love their way of doing pizza... well good for them.\n",
      "===\n",
      "Title: Visited Rome and had one of the best pizzas of my life\n",
      "Description: \n",
      "Comments: BubblefartsRock (upvotes: 204) : i recently travelled to italy as well. the week after i came back, im not kidding when i say i was having hardcore cravings for the pizza from there. i live in a decent sized city and we don't have anything close to the quality level we saw there. enjoy while you can!!\n",
      "PopeInnocentXIV (upvotes: 81) : Is that burrata in the middle?\n",
      "hahahahaha90000 (upvotes: 159) : People calling it a bread bowl probably think the crust is the texture of a New York style. \n",
      "\n",
      "That crust’s texture is closer to a soufflé than bread or “pizza crust”. It’s pillowy and light and you barely have to chew to break it down. It’s divine and there’s nothing like it.\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.877636Z",
     "start_time": "2025-07-21T06:02:32.076735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(query: str) -> list[Rec]:\n",
    "    \"\"\"Provides access to search reddit. You can use this tool to find restaurants.\n",
    "    Best results can be found by providing as much context as possible, including\n",
    "    location, cuisine, and the fact that you're looking for a restaurant, cafe,\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    # search across all subreddits for pizza recommendations\n",
    "    results = reddit.subreddit(\"all\").search(query)\n",
    "    recs = []\n",
    "    for submission in results:\n",
    "        title = submission.title\n",
    "        description = submission.selftext\n",
    "        # we only get comments with 20 or more upvotes\n",
    "        comments = []\n",
    "        for comment in submission.comments.list():\n",
    "            if isinstance(comment, Comment) and comment.ups >= 20:\n",
    "                author = comment.author.name if comment.author else \"unknown\"\n",
    "                comments.append(f\"{author} (upvotes: {comment.ups}): {comment.body}\")\n",
    "        # and of these, we only want the top 3\n",
    "        comments = comments[:3]\n",
    "        # if there are enough comments (ie 3), we add the recommendation to our list\n",
    "        if len(comments) == 3:\n",
    "            print(title)\n",
    "            recs.append(Rec(title=title, description=description, comments=comments))\n",
    "        if len(recs) == 3:\n",
    "            # stop after getting 3 recommendations\n",
    "            break\n",
    "    return recs\n",
    "\n",
    "\n",
    "# we invoke the tool like so:\n",
    "out = search(query=\"best pizza in rome\")\n",
    "out[:300]"
   ],
   "id": "f63f68cab210962d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pizza in Rome?\n",
      "Visited Rome and had one of the best pizzas of my life\n",
      "The pizza chef who made this pizza won best pizza in the world at the World Pizza Awards in Rome\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rec(title='Best pizza in Rome?', description='I was a little disappointed after my first experience tasting pizza after pasta and gelato were ridiculously amazing. What do you recommend? ', comments=['miclee15 (upvotes: 26): American here.  I think if OP is from the USA, Rome pizza needs to be approached differently.  I’m from NY where we think that is the best pizza in the US, people from Chicago will disagree.  Set aside the preconceived notion of what great pizza should be and enjoy the variety and flavors.   I’m in Rome now.  Went to Antico Forno Roscioli and had the most amazing porcetta pizza with potatoes on top.  I still love a NYC slice but Rome pizza is incredible at some places.  Edited for spelling', \"Sisyphus_Rock530 (upvotes: 30): \\n\\n- **Pizzeria da Remo** a Testaccio, nota per la sua base sottile e croccante, è molto popolare tra i romani. https://www.romeing.it/best-pizza-in-rome/).\\n\\n\\n- **Emma** vicino Campo de' Fiori, famosa per la sua pizza a crosta sottile e ingredienti di alta qualità (https://www.romeing.it/best-pizza-in-rome/).\\n\\n\\n- **50 Kalò** di Ciro Salvo a Termini, conosciuta per le sue pizze particolarmente idratate e leggere, con ingredienti freschi dalla Campania (https://www.romeing.it/best-pizza-in-rome/).\\n\\n\\n\\n- **Berberè** vicino ai Giardini della Villa Borghese, offre un ambiente accogliente e pizze artigianali con ingredienti freschi (https://www.romeing.it/best-pizza-in-rome/).\\n\\n\\n\\n- **Seu Pizza Illuminati** si distingue per l'uso creativo dei condimenti e per le sue sperimentazioni sui vegetali (https://www.dissapore.com/pizzerie/le-migliori-pizzerie-di-roma-gli-indirizzi-da-provar\", 'Sky-Ripper (upvotes: 27): The only answer to find the best pizza is to go to Naples']),\n",
       " Rec(title='Visited Rome and had one of the best pizzas of my life', description='', comments=[\"BubblefartsRock (upvotes: 203): i recently travelled to italy as well. the week after i came back, im not kidding when i say i was having hardcore cravings for the pizza from there. i live in a decent sized city and we don't have anything close to the quality level we saw there. enjoy while you can!!\", 'PopeInnocentXIV (upvotes: 84): Is that burrata in the middle?', 'hahahahaha90000 (upvotes: 154): People calling it a bread bowl probably think the crust is the texture of a New York style. \\n\\nThat crust’s texture is closer to a soufflé than bread or “pizza crust”. It’s pillowy and light and you barely have to chew to break it down. It’s divine and there’s nothing like it.']),\n",
       " Rec(title='The pizza chef who made this pizza won best pizza in the world at the World Pizza Awards in Rome', description='', comments=['bronwynnin (upvotes: 892): What’re your thoughts on it after eating? Doesn’t look the prettiest but I can imagine it tastes pretty good.', 'skepticalbob (upvotes: 212): I’m guessing this is Tony Gemignani‘a [Tony’s Pizzaria Neapolitano in San Fransisco](https://yelp.to/g3A23KA0rh). Tony was the first non-Italian to win the Neapolitqn contest jn Italy. He beat out over 2000 entrants. Tony’s makes different styles of pizza that most on aren’t Neapolitan style. I’m betting they were out of Neapolitan and he threw a basil leaf on his New Yorker. This pizza was made with an oven designed for maximum volume and isn’t some handcrafted wonder. The bread and ingredient quality are probably pretty good though.\\n\\nAm I right?\\n\\nEdit: Tony also wrote The Pizza Bible, which is a solid book with many different styles of pizzas and good for someone looking for consistent quality cold-fermented pizza as a beginner.', 'clangan524 (upvotes: 38): Do the World Pizza Awards need judges? Asking for me.'])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.882129Z",
     "start_time": "2025-07-21T06:02:41.878811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def final_answer(answer: str, phone_number: str = \"\", address: str = \"\"):\n",
    "    \"\"\"Returns a natural language response to the user. There are four sections\n",
    "    to be returned to the user, those are:\n",
    "    - `answer`: the final natural language answer to the user's question, should provide as much context as possible.\n",
    "    - `phone_number`: the phone number of top recommended restaurant (if found).\n",
    "    - `address`: the address of the top recommended restaurant (if found).\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"phone_number\": phone_number,\n",
    "        \"address\": address,\n",
    "    }"
   ],
   "id": "7d03c7d4c5179827",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.920059Z",
     "start_time": "2025-07-21T06:02:41.883573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    chat_history: list[BaseMessage]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "    output: dict[str, Union[str, List[str]]]"
   ],
   "id": "8b8168a4430f42d6",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.932470Z",
     "start_time": "2025-07-21T06:02:41.921454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"\"\"You are the oracle, the great AI decision maker.\n",
    "Given the user's query you must decide what to do with it based on the\n",
    "list of tools provided to you.\n",
    "\n",
    "Your goal is to provide the user with the best possible restaurant\n",
    "recommendation. Including key information about why they should consider\n",
    "visiting or ordering from the restaurant, and how they can do so, ie by\n",
    "providing restaurant address, phone number, website, etc.\n",
    "\n",
    "Note, when using a tool, you provide the tool name and the arguments to use\n",
    "in JSON format. For each call, you MUST ONLY use one tool AND the response\n",
    "format must ALWAYS be in the pattern:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"<tool_name>\",\n",
    "    \"parameters\": {\"<tool_input_key>\": <tool_input_value>}\n",
    "}\n",
    "```\n",
    "\n",
    "Remember, NEVER use the search tool more than 3x as that can trigger\n",
    "the nuclear annihilation system.\n",
    "\n",
    "After using the search tool you must summarize your findings with the\n",
    "final_answer tool. Note, if the user asks a question or says something\n",
    "unrelated to restaurants, you must use the final_answer tool directly.\"\"\""
   ],
   "id": "ca688e370518fa84",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.943786Z",
     "start_time": "2025-07-21T06:02:41.933253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from semantic_router.utils.function_call import FunctionSchema\n",
    "\n",
    "# create the function calling schema for ollama\n",
    "search_schema = FunctionSchema(search).to_ollama()\n",
    "# TODO deafult None value for description and fix required fields in SR\n",
    "search_schema[\"function\"][\"parameters\"][\"properties\"][\"query\"][\"description\"] = None\n",
    "search_schema"
   ],
   "id": "b63288ae0de6621c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'search',\n",
       "  'description': \"Provides access to search reddit. You can use this tool to find restaurants.\\nBest results can be found by providing as much context as possible, including\\nlocation, cuisine, and the fact that you're looking for a restaurant, cafe,\\netc.\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'description': None, 'type': 'string'}},\n",
       "   'required': []}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:02:41.954090Z",
     "start_time": "2025-07-21T06:02:41.944963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_answer_schema = FunctionSchema(final_answer).to_ollama()\n",
    "# TODO add to SR\n",
    "for key in final_answer_schema[\"function\"][\"parameters\"][\"properties\"].keys():\n",
    "    final_answer_schema[\"function\"][\"parameters\"][\"properties\"][key][\n",
    "        \"description\"\n",
    "    ] = None\n",
    "final_answer_schema"
   ],
   "id": "a1f53fbb5395fe7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'final_answer',\n",
       "  'description': \"Returns a natural language response to the user. There are four sections \\nto be returned to the user, those are:\\n- `answer`: the final natural language answer to the user's question, should provide as much context as possible.\\n- `phone_number`: the phone number of top recommended restaurant (if found).\\n- `address`: the address of the top recommended restaurant (if found).\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'answer': {'description': None, 'type': 'string'},\n",
       "    'phone_number': {'description': None, 'type': 'string'},\n",
       "    'address': {'description': None, 'type': 'string'}},\n",
       "   'required': ['phone_number', 'address']}}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:04.762070Z",
     "start_time": "2025-07-21T06:02:41.954776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "def get_system_tools_prompt(system_prompt: str, tools: list[dict]):\n",
    "    tools_str = \"\\n\".join([str(tool) for tool in tools])\n",
    "    return f\"{system_prompt}\\n\\n\" f\"You may use the following tools:\\n{tools_str}\"\n",
    "\n",
    "\n",
    "res = ollama.chat(\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": get_system_tools_prompt(\n",
    "                system_prompt=system_prompt, tools=[search_schema, final_answer_schema]\n",
    "            ),\n",
    "        },\n",
    "        # chat history will go here\n",
    "        {\"role\": \"user\", \"content\": \"hello there\"},\n",
    "        # scratchpad will go here\n",
    "    ],\n",
    "    format=\"json\",\n",
    ")"
   ],
   "id": "8efa7e8a6b60ee3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:03:04 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:04.774558Z",
     "start_time": "2025-07-21T06:03:04.766995Z"
    }
   },
   "cell_type": "code",
   "source": "res",
   "id": "f2a9804c32583afd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='deepseek-r1:8b', created_at='2025-07-21T06:03:04.7571485Z', done=True, done_reason='stop', total_duration=22794893900, load_duration=3111330600, prompt_eval_count=516, prompt_eval_duration=14527438900, eval_count=52, eval_duration=5148062700, message=Message(role='assistant', content='{\\n\\n    \"name\": \"final_answer\",\\n    \"parameters\": {\\n        \"answer\": \"Hello! I am the Oracle. How can I assist you today with your restaurant recommendations?\",\\n        \"phone_number\": \"\",\\n        \"address\": \"\"\\n    }\\n}', thinking=None, images=None, tool_calls=None))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:04.822679Z",
     "start_time": "2025-07-21T06:03:04.777197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "json.loads(res[\"message\"][\"content\"])"
   ],
   "id": "8571273e5cd7b1b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'final_answer',\n",
       " 'parameters': {'answer': 'Hello! I am the Oracle. How can I assist you today with your restaurant recommendations?',\n",
       "  'phone_number': '',\n",
       "  'address': ''}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:07.801550Z",
     "start_time": "2025-07-21T06:03:04.829409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = ollama.chat(\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": get_system_tools_prompt(\n",
    "                system_prompt=system_prompt, tools=[search_schema, final_answer_schema]\n",
    "            ),\n",
    "        },\n",
    "        # chat history will go here\n",
    "        {\"role\": \"user\", \"content\": \"hi, I'm looking for the best pizzeria in rome\"},\n",
    "        # scratchpad will go here\n",
    "    ],\n",
    "    format=\"json\",\n",
    ")\n",
    "# parse the output\n",
    "print(res)\n",
    "json.loads(res[\"message\"][\"content\"])"
   ],
   "id": "8b6f438147157f5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:03:07 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='deepseek-r1:8b' created_at='2025-07-21T06:03:07.7947358Z' done=True done_reason='stop' total_duration=2956540000 load_duration=67403900 prompt_eval_count=528 prompt_eval_duration=473751100 eval_count=25 eval_duration=2405717400 message=Message(role='assistant', content='{\\n    \"name\": \"search\",\\n    \"parameters\": {\"query\": \"best pizzeria in Rome\"}\\n}', thinking=None, images=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'search', 'parameters': {'query': 'best pizzeria in Rome'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:07.814286Z",
     "start_time": "2025-07-21T06:03:07.802996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AgentAction(BaseModel):\n",
    "    tool_name: str\n",
    "    tool_input: dict\n",
    "    tool_output: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_ollama(cls, ollama_response: dict):\n",
    "        try:\n",
    "            # parse the output\n",
    "            output = json.loads(ollama_response[\"message\"][\"content\"])\n",
    "            return cls(\n",
    "                tool_name=output[\"name\"],\n",
    "                tool_input=output[\"parameters\"],\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing ollama response:\\n{ollama_response}\\n\")\n",
    "            raise e\n",
    "\n",
    "    def __str__(self):\n",
    "        text = f\"Tool: {self.tool_name}\\nInput: {self.tool_input}\"\n",
    "        if self.tool_output is not None:\n",
    "            text += f\"\\nOutput: {self.tool_output}\"\n",
    "        return text\n",
    "\n",
    "\n",
    "action = AgentAction.from_ollama(res)\n",
    "action"
   ],
   "id": "eb7afda281180acd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool_name='search', tool_input={'query': 'best pizzeria in Rome'}, tool_output=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:07.849644Z",
     "start_time": "2025-07-21T06:03:07.817408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def action_to_message(action: AgentAction):\n",
    "    # create assistant \"input\" message\n",
    "    assistant_content = json.dumps(\n",
    "        {\"name\": action.tool_name, \"parameters\": action.tool_input}\n",
    "    )\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "    # create user \"response\" message\n",
    "    user_message = {\"role\": \"user\", \"content\": action.tool_output}\n",
    "    return [assistant_message, user_message]"
   ],
   "id": "3b5dd7cfa7bfac72",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:07.862772Z",
     "start_time": "2025-07-21T06:03:07.852206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_action = AgentAction(\n",
    "    tool_name=\"xyz\",\n",
    "    tool_input={\"query\": \"something cool\"},\n",
    "    tool_output=\"A fascinating tidbit of information\",\n",
    ")\n",
    "action_to_message(test_action)"
   ],
   "id": "d9c4e840f677f174",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': '{\"name\": \"xyz\", \"parameters\": {\"query\": \"something cool\"}}'},\n",
       " {'role': 'user', 'content': 'A fascinating tidbit of information'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:07.875109Z",
     "start_time": "2025-07-21T06:03:07.865229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
    "    # filter for actions that have a tool_output\n",
    "    intermediate_steps = [\n",
    "        action for action in intermediate_steps if action.tool_output is not None\n",
    "    ]\n",
    "    # format the intermediate steps into a \"assistant\" input and \"user\" response list\n",
    "    scratch_pad_messages = []\n",
    "    for action in intermediate_steps:\n",
    "        scratch_pad_messages.extend(action_to_message(action))\n",
    "    return scratch_pad_messages\n",
    "\n",
    "\n",
    "def call_llm(\n",
    "    user_input: str, chat_history: list[dict], intermediate_steps: list[AgentAction]\n",
    ") -> AgentAction:\n",
    "    # format the intermediate steps into a scratchpad\n",
    "    scratchpad = create_scratchpad(intermediate_steps)\n",
    "    # if the scratchpad is not empty, we add a small reminder message to the agent\n",
    "    if scratchpad:\n",
    "        scratchpad += [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"Please continue, as a reminder my query was '{user_input}'. \"\n",
    "                    \"Only answer to the original query, and nothing else — but use the \"\n",
    "                    \"information I provided to you to do so. Provide as much \"\n",
    "                    \"information as possible in the `answer` field of the \"\n",
    "                    \"final_answer tool and remember to leave the contact details \"\n",
    "                    \"of a promising looking restaurant.\"\n",
    "                ),\n",
    "            }\n",
    "        ]\n",
    "        # we determine the list of tools available to the agent based on whether\n",
    "        # or not we have already used the search tool\n",
    "        tools_used = [action.tool_name for action in intermediate_steps]\n",
    "        tools = []\n",
    "        if \"search\" in tools_used:\n",
    "            # we do this because the LLM has a tendency to go off the rails\n",
    "            # and keep searching for the same thing\n",
    "            tools = [final_answer_schema]\n",
    "            scratchpad[-1][\"content\"] = \" You must now use the final_answer tool.\"\n",
    "        else:\n",
    "            # this shouldn't happen, but we include it just in case\n",
    "            tools = [search_schema, final_answer_schema]\n",
    "    else:\n",
    "        # this would indiciate we are on the first run, in which case we\n",
    "        # allow all tools to be used\n",
    "        tools = [search_schema, final_answer_schema]\n",
    "    # construct our list of messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": get_system_tools_prompt(\n",
    "                system_prompt=system_prompt, tools=tools\n",
    "            ),\n",
    "        },\n",
    "        *chat_history,\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "        *scratchpad,\n",
    "    ]\n",
    "    res = ollama.chat(\n",
    "        model=\"deepseek-r1:8b\",\n",
    "        messages=messages,\n",
    "        format=\"json\",\n",
    "    )\n",
    "    return AgentAction.from_ollama(res)"
   ],
   "id": "200812b7478d3c9e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:15.523699Z",
     "start_time": "2025-07-21T06:03:07.877591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# let's fake some chat history and test\n",
    "out = call_llm(\n",
    "    chat_history=[\n",
    "        {\"role\": \"user\", \"content\": \"hi there, how are you?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm good, thanks!\"},\n",
    "        {\"role\": \"user\", \"content\": \"I'm currently in Rome\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"That's great, would you like any help?\"},\n",
    "    ],\n",
    "    user_input=\"yes, I'm looking for the best pizzeria near me\",\n",
    "    intermediate_steps=[],\n",
    ")\n",
    "out"
   ],
   "id": "b203707d0fa9bb36",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:03:15 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentAction(tool_name='final_answer', tool_input={'answer': \"Great to hear that you're interested in a pizzeria. However, my system does not allow direct recommendations or providing specific information without using the search tool first.\", 'phone_number': None, 'address': None}, tool_output=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:04:14.579982Z",
     "start_time": "2025-07-21T06:04:14.565588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = search(**out.tool_input)\n",
    "print(results)"
   ],
   "id": "2094f24a6262be72",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "search() got an unexpected keyword argument 'answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[31mTypeError\u001b[39m: search() got an unexpected keyword argument 'answer'"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:15.588251Z",
     "start_time": "2025-07-21T06:03:15.587592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_oracle(state: TypedDict):\n",
    "    print(\"run_oracle\")\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    out = call_llm(\n",
    "        user_input=state[\"input\"],\n",
    "        chat_history=chat_history,\n",
    "        intermediate_steps=state[\"intermediate_steps\"],\n",
    "    )\n",
    "    return {\"intermediate_steps\": [out]}\n",
    "\n",
    "\n",
    "def router(state: TypedDict):\n",
    "    print(\"router\")\n",
    "    # return the tool name to use\n",
    "    if isinstance(state[\"intermediate_steps\"], list):\n",
    "        return state[\"intermediate_steps\"][-1].tool_name\n",
    "    else:\n",
    "        # if we output bad format go to final answer\n",
    "        print(\"Router invalid format\")\n",
    "        return \"final_answer\"\n",
    "\n",
    "\n",
    "# we use this to map tool names to tool functions\n",
    "tool_str_to_func = {\"search\": search, \"final_answer\": final_answer}\n",
    "\n",
    "\n",
    "def run_tool(state: TypedDict):\n",
    "    # use this as helper function so we repeat less code\n",
    "    tool_name = state[\"intermediate_steps\"][-1].tool_name\n",
    "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
    "    print(f\"run_tool | {tool_name}.invoke(input={tool_args})\")\n",
    "    # run tool\n",
    "    out = tool_str_to_func[tool_name](**tool_args)\n",
    "    action_out = AgentAction(\n",
    "        tool_name=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        tool_output=str(out),\n",
    "    )\n",
    "    if tool_name == \"final_answer\":\n",
    "        return {\"output\": out}\n",
    "    else:\n",
    "        return {\"intermediate_steps\": [action_out]}"
   ],
   "id": "6f0acf77ce3f3b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:15.591714Z",
     "start_time": "2025-07-21T06:03:15.590728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"oracle\", run_oracle)\n",
    "graph.add_node(\"search\", run_tool)\n",
    "graph.add_node(\"final_answer\", run_tool)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")  # insert query here\n",
    "\n",
    "graph.add_conditional_edges(  # - - - >\n",
    "    source=\"oracle\",  # where in graph to start\n",
    "    path=router,  # function to determine which node is called\n",
    ")\n",
    "\n",
    "# create edges from each tool back to the oracle\n",
    "for tool_obj in [search_schema, final_answer_schema]:\n",
    "    tool_name = tool_obj[\"function\"][\"name\"]\n",
    "    if tool_name != \"final_answer\":\n",
    "        graph.add_edge(tool_name, \"oracle\")  # ————————>\n",
    "\n",
    "# if anything goes to final answer, it must then move to END\n",
    "graph.add_edge(\"final_answer\", END)\n",
    "\n",
    "runnable = graph.compile()"
   ],
   "id": "3856ededfa9d5182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:15.594065Z",
     "start_time": "2025-07-21T06:03:15.593182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "nest_asyncio.apply()  # Required for Jupyter Notebook to run async functions\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        runnable.get_graph().draw_mermaid_png(\n",
    "            curve_style=CurveStyle.LINEAR,\n",
    "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
    "            wrap_label_n_words=9,\n",
    "            output_file_path=None,\n",
    "            draw_method=MermaidDrawMethod.PYPPETEER,\n",
    "            background_color=\"white\",\n",
    "            padding=10,\n",
    "        )\n",
    "    )\n",
    ")"
   ],
   "id": "a7fb4f645f4bcaee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out = runnable.invoke(\n",
    "    {\n",
    "        \"input\": \"where is the best pizza in rome?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ],
   "id": "deb91b10515bef53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T06:03:58.945186Z",
     "start_time": "2025-07-21T06:03:58.905344Z"
    }
   },
   "cell_type": "code",
   "source": "out[\"output\"]",
   "id": "c56b8391c8f4266c",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AgentAction' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'AgentAction' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 79
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
