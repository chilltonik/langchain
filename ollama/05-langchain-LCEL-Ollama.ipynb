{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain Essentials Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChains Expression Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain is one of the most popular open source libraries for AI Engineers. It's goal is to abstract away the complexity in building AI software, provide easy-to-use building blocks, and make it easier when switching between AI service providers.\n",
    "\n",
    "In this example, we will introduce LangChain's Expression Langauge (LCEL), abstracting a full chain and understanding how it will work. We'll provide examples for both OpenAI's `gpt-4o-mini` *and* Meta's `llama3.2` via Ollama!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is split into two versions - The [Ollama version](), allowing us to run our LLM locally without needing any external services or API keys. The [OpenAI version](https://github.com/aurelio-labs/agents-course/blob/main/04-langchain-ecosystem/01-langchain-essentials/01-langchain-intro-openai.ipynb) uses the OpenAI API and requires an OpenAI API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Llama 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing the 1B parameter Llama 3.2 model, fine-tuned for instruction following. We pull the model from Ollama by switching to our terminal and executing:\n",
    "\n",
    "ollama pull llama3.2:1b-instruct-fp16\n",
    "\n",
    "Once the model has finished downloading, we initialize it in LangChain using the ChatOllama class:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:44:39.732102Z",
     "start_time": "2025-06-12T15:44:39.725555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:46:02.219281Z",
     "start_time": "2025-06-12T15:46:01.592156Z"
    }
   },
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2:1b\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)\n",
    "\n",
    "# initialize another LLM with temperature 0.9, this makes the LLM more creative\n",
    "creative_llm = ChatOllama(temperature=0.9, model=model_name)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Chains vs LCEL Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we're going to dive into a basic example comparing the main difference between the two chains. For this we will use a basic example of finding the user's report, where the user must input a specific topic, and then the LLM will look and return a report on the specified topic."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:46:04.377415Z",
     "start_time": "2025-06-12T15:46:04.373649Z"
    }
   },
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:46:04.919814Z",
     "start_time": "2025-06-12T15:46:04.916393Z"
    }
   },
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"Give me a small report of {topic}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a standard LLMChain, this has the basic function like properties where we would call a name of the function, and pass in parameters to adjust the function, in this case, prompt, llm and output_parser, where the prompt will be used by the model, and then the result of the model will be used by the output parser."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:46:06.372834Z",
     "start_time": "2025-06-12T15:46:06.370096Z"
    }
   },
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    prompt = prompt,\n",
    "    llm = llm,\n",
    "    output_parser = output_parser\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:46:23.506554Z",
     "start_time": "2025-06-12T15:46:08.113255Z"
    }
   },
   "source": [
    "result = chain.invoke(\"AI\")\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'AI', 'text': \"Here's a brief report on Artificial Intelligence (AI):\\n\\n**What is Artificial Intelligence?**\\n\\nArtificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception. AI systems use algorithms and data to make decisions, learn from experience, and improve their performance over time.\\n\\n**Types of AI:**\\n\\n1. **Narrow or Weak AI:** Designed to perform a specific task, such as facial recognition, language translation, or playing chess.\\n2. **General or Strong AI:** A hypothetical AI system that can perform any intellectual task that a human can, with no limitations.\\n3. **Superintelligence:** An AI system that is significantly more intelligent than the best human minds.\\n\\n**AI Techniques:**\\n\\n1. **Machine Learning (ML):** A subset of AI that enables systems to learn from data and improve their performance over time.\\n2. **Deep Learning (DL):** A type of ML that uses neural networks to analyze complex data.\\n3. **Natural Language Processing (NLP):** The ability of AI systems to understand, interpret, and generate human language.\\n\\n**Applications of AI:**\\n\\n1. **Virtual Assistants:** Siri, Alexa, and Google Assistant use AI to perform tasks such as scheduling appointments and sending messages.\\n2. **Image Recognition:** AI-powered systems can recognize objects, people, and text in images.\\n3. **Predictive Analytics:** AI helps businesses predict customer behavior, sales trends, and other key performance indicators.\\n4. **Autonomous Vehicles:** Self-driving cars use AI to navigate roads, detect obstacles, and make decisions.\\n\\n**Challenges and Concerns:**\\n\\n1. **Job Displacement:** AI may automate jobs, leading to unemployment and social disruption.\\n2. **Bias and Fairness:** AI systems can perpetuate biases if trained on biased data or designed with a particular worldview.\\n3. **Security Risks:** AI-powered systems can be vulnerable to cyber attacks and data breaches.\\n\\n**Future of AI:**\\n\\n1. **Increased Adoption:** AI is expected to become more widespread in industries such as healthcare, finance, and education.\\n2. **Advancements in Ethics:** Researchers are working on developing AI systems that prioritize ethics and transparency.\\n3. **Addressing Challenges:** Efforts are being made to address job displacement, bias, and security risks through the development of more transparent and explainable AI systems.\\n\\nThis report provides a brief overview of Artificial Intelligence, its types, techniques, applications, challenges, and future prospects.\"}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a LCEL chain, as you can see, this initially appears to be abit 'hacky' but the abstraction allows for us to skip calling a function and pass our variables into eachother instead."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:48:24.003461Z",
     "start_time": "2025-06-12T15:48:24.000505Z"
    }
   },
   "source": [
    "lcel_chain = prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:48:39.257219Z",
     "start_time": "2025-06-12T15:48:25.712814Z"
    }
   },
   "source": [
    "result = lcel_chain.invoke(\"AI\")\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a brief report on Artificial Intelligence (AI):\n",
      "\n",
      "**What is Artificial Intelligence?**\n",
      "\n",
      "Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception. AI systems use algorithms and data to make decisions, learn from experience, and improve their performance over time.\n",
      "\n",
      "**Types of AI:**\n",
      "\n",
      "1. **Narrow or Weak AI:** Designed to perform a specific task, such as facial recognition, language translation, or playing chess.\n",
      "2. **General or Strong AI:** A hypothetical AI system that can perform any intellectual task that a human can, with no limitations.\n",
      "3. **Superintelligence:** An AI system that is significantly more intelligent than the best human minds.\n",
      "\n",
      "**AI Techniques:**\n",
      "\n",
      "1. **Machine Learning (ML):** A subset of AI that enables systems to learn from data and improve their performance over time.\n",
      "2. **Deep Learning (DL):** A type of ML that uses neural networks to analyze complex data.\n",
      "3. **Natural Language Processing (NLP):** The ability of AI systems to understand, interpret, and generate human language.\n",
      "\n",
      "**Applications of AI:**\n",
      "\n",
      "1. **Virtual Assistants:** Siri, Alexa, and Google Assistant use AI to perform tasks such as scheduling appointments and sending messages.\n",
      "2. **Image Recognition:** AI-powered systems can recognize objects, people, and text in images.\n",
      "3. **Predictive Analytics:** AI helps businesses predict customer behavior, sales trends, and other key performance indicators.\n",
      "4. **Autonomous Vehicles:** Self-driving cars use AI to navigate roads, detect obstacles, and make decisions.\n",
      "\n",
      "**Challenges and Concerns:**\n",
      "\n",
      "1. **Job Displacement:** AI may automate jobs, leading to unemployment and social disruption.\n",
      "2. **Bias and Fairness:** AI systems can perpetuate biases if trained on biased data or designed with a particular worldview.\n",
      "3. **Security Risks:** AI-powered systems can be vulnerable to cyber attacks and data breaches.\n",
      "\n",
      "**Future of AI:**\n",
      "\n",
      "1. **Increased Adoption:** AI is expected to become more widespread in industries such as healthcare, finance, and education.\n",
      "2. **Advancements in Ethics:** Researchers are working on developing AI systems that prioritize ethics and transparency.\n",
      "3. **Addressing Challenges:** Efforts are being made to address job displacement, bias, and security risks through the development of more transparent and explainable AI systems.\n",
      "\n",
      "This report provides a brief overview of Artificial Intelligence, its types, techniques, applications, challenges, and future prospects.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Does LCEL Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept is reasonably simple, you start on the far left side of the line, look at the first variable, and the output to that variable is passed into the next variable, before we had ***prompt | llm | output_parser***, we can see that the prompt, feeds into the model, then the model result feeds into the output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the pipe operator **|** we are basically looking for a or function, this is where we can find a chained functionallity to the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a basic runnable class to show you the basics of how this works."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:49:35.209898Z",
     "start_time": "2025-06-12T15:49:35.206195Z"
    }
   },
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly want to make a bunch of random functions, in this case we will do some simple maths with each function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:50:19.234099Z",
     "start_time": "2025-06-12T15:50:19.231142Z"
    }
   },
   "source": [
    "def add_five(x):\n",
    "    return x+5\n",
    "def sub_five(x):\n",
    "    return x-5\n",
    "def mul_five(x):\n",
    "    return x*5"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to coat our functions with the runnable so that the or function can be identified."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:50:30.206533Z",
     "start_time": "2025-06-12T15:50:30.203240Z"
    }
   },
   "source": [
    "add_five = Runnable(add_five)\n",
    "sub_five = Runnable(sub_five)\n",
    "mul_five = Runnable(mul_five)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as you can see we can chain together the 3 functions we made just earlier using the or function, and if we switch the or functions out for the pipe operator, it does exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:52:00.491967Z",
     "start_time": "2025-06-12T15:52:00.483903Z"
    }
   },
   "source": [
    "chain = (add_five).__or__(sub_five).__or__(mul_five)\n",
    "chain(3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T15:52:01.154381Z",
     "start_time": "2025-06-12T15:52:01.150439Z"
    }
   },
   "source": [
    "chain = add_five | sub_five | mul_five\n",
    "chain(3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Parallel Use-Case Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will go over how we can use LCEL's parallel capabilities.\n",
    "\n",
    "To start us of with, we will have two statements, one side telling the AI the month and day Josh was born, and the other telling the AI the year Josh was born. We will then embed the statements and feed them into AI together."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:06:04.072559Z",
     "start_time": "2025-06-12T16:05:51.419859Z"
    }
   },
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "embedding = OllamaEmbeddings()\n",
    "vecstore_a = DocArrayInMemorySearch.from_texts(\n",
    "    [\"half the info is here\", \"Joshs' birthday is June the 12th\"], \n",
    "    embedding=embedding\n",
    ")\n",
    "vecstore_b = DocArrayInMemorySearch.from_texts(\n",
    "    [\"the other half of the info is here\", \"Josh was born in 2002\"], \n",
    "    embedding=embedding\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the prompt does have three inputs, two for context and one for the question itself."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:06:14.771381Z",
     "start_time": "2025-06-12T16:06:14.766738Z"
    }
   },
   "source": [
    "prompt_str = \"\"\" using the following context answer the question\n",
    "Context: \n",
    "{context_a}\n",
    "{context_b}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer: \"\"\""
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:06:19.553407Z",
     "start_time": "2025-06-12T16:06:19.493017Z"
    }
   },
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are wrapping our vector stores as retrievers so they can be fitted into one big retrieval variable to be used by the prompt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:06:51.941412Z",
     "start_time": "2025-06-12T16:06:51.937804Z"
    }
   },
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b, \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:06:59.297521Z",
     "start_time": "2025-06-12T16:06:59.295167Z"
    }
   },
   "source": [
    "chain = retrieval | prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:07:10.156994Z",
     "start_time": "2025-06-12T16:07:03.183001Z"
    }
   },
   "source": [
    "result = chain.invoke(\"What was the date when Josh was born\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:07:13.605784Z",
     "start_time": "2025-06-12T16:07:13.601804Z"
    }
   },
   "source": [
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, we can infer that the information about Josh\\'s birthdate is split between two documents. \\n\\nThe first document states that \"half the info is here\", which implies that it contains only one part of the information about Josh\\'s birthdate.\\n\\nThe second document explicitly states that \"the other half of the info is here\", which means it contains the complete information about Josh\\'s birthdate.\\n\\nTherefore, we can conclude that the date when Josh was born is mentioned in the first document.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain's RunnableLambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use arbitrary functions as Runnables. This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called RunnableLambdas.\n",
    "\n",
    "Note that all inputs to these functions need to be a SINGLE argument. If you have a function that accepts multiple arguments, you should write a wrapper that accepts a single dict input and unpacks it into multiple arguments."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:08:20.615771Z",
     "start_time": "2025-06-12T16:08:20.612406Z"
    }
   },
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can make some custom functions that do simple maths again, and see that RunnableLambdas can compile and output the correct results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:08:45.003622Z",
     "start_time": "2025-06-12T16:08:44.998209Z"
    }
   },
   "source": [
    "def add_five(x):\n",
    "    return x+5\n",
    "def sub_five(x):\n",
    "    return x-5\n",
    "def mul_five(x):\n",
    "    return x*5"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:08:47.554137Z",
     "start_time": "2025-06-12T16:08:47.550147Z"
    }
   },
   "source": [
    "add_five = RunnableLambda(add_five)\n",
    "sub_five = RunnableLambda(sub_five)\n",
    "mul_five = RunnableLambda(mul_five)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:10.074301Z",
     "start_time": "2025-06-12T16:09:10.071096Z"
    }
   },
   "source": [
    "chain = add_five | sub_five | mul_five"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:14.754062Z",
     "start_time": "2025-06-12T16:09:14.745672Z"
    }
   },
   "source": [
    "chain.invoke(3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try something a little more testing, so this time we will generate a report, and we will try and edit that report using this functionallity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:28.304495Z",
     "start_time": "2025-06-12T16:09:28.300814Z"
    }
   },
   "source": [
    "prompt_str = \"give me a small report about {topic}\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_str\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:28.875043Z",
     "start_time": "2025-06-12T16:09:28.871325Z"
    }
   },
   "source": [
    "chain = prompt | llm | output_parser"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:41.883340Z",
     "start_time": "2025-06-12T16:09:29.901349Z"
    }
   },
   "source": [
    "result = chain.invoke(\"AI\")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:09:46.582883Z",
     "start_time": "2025-06-12T16:09:46.579779Z"
    }
   },
   "source": [
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a brief report on Artificial Intelligence (AI):\n",
      "\n",
      "**What is Artificial Intelligence?**\n",
      "\n",
      "Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception. AI systems use algorithms and data to make decisions, identify patterns, and learn from experience.\n",
      "\n",
      "**Types of AI:**\n",
      "\n",
      "1. **Narrow or Weak AI:** Designed to perform a specific task, such as facial recognition, language translation, or playing chess.\n",
      "2. **General or Strong AI:** A hypothetical AI system that can perform any intellectual task that humans can, with no limitations.\n",
      "3. **Superintelligence:** An AI system that is significantly more intelligent than the best human minds.\n",
      "\n",
      "**AI Applications:**\n",
      "\n",
      "1. **Virtual Assistants:** Siri, Alexa, and Google Assistant use AI to understand voice commands and respond accordingly.\n",
      "2. **Image Recognition:** AI-powered systems like Facebook's facial recognition feature and Google Photos' image tagging allow for automatic identification of objects and people in images.\n",
      "3. **Predictive Analytics:** AI algorithms analyze data to predict customer behavior, detect anomalies, and optimize business processes.\n",
      "4. **Robotics:** AI-controlled robots can perform tasks such as assembly, maintenance, and healthcare.\n",
      "\n",
      "**Challenges and Concerns:**\n",
      "\n",
      "1. **Job Displacement:** AI may automate jobs, leading to unemployment and social disruption.\n",
      "2. **Bias and Fairness:** AI systems can perpetuate biases if trained on biased data or designed with a particular worldview.\n",
      "3. **Security Risks:** AI-powered systems can be vulnerable to cyber attacks and data breaches.\n",
      "\n",
      "**Future of AI:**\n",
      "\n",
      "1. **Increased Adoption:** AI is expected to become more widespread in industries such as healthcare, finance, and transportation.\n",
      "2. **Advancements in Natural Language Processing (NLP):** NLP will continue to improve, enabling AI systems to understand and generate human-like language.\n",
      "3. **Ethics and Governance:** As AI becomes more pervasive, there will be a growing need for regulations and guidelines to ensure responsible development and deployment of AI.\n",
      "\n",
      "This report provides an overview of the current state of Artificial Intelligence, its applications, challenges, and future prospects.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are making two functions, one that will get rid of the introduction to the AI finding the information, instead we will just see the information, and word replacer that will replace AI with Josh!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:10:08.896341Z",
     "start_time": "2025-06-12T16:10:08.891936Z"
    }
   },
   "source": [
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "old_word = \"AI\"\n",
    "new_word = \"Josh\"\n",
    "\n",
    "def replace_word(x):\n",
    "    return x.replace(old_word, new_word)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets wrap these functions and see what the output is!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:10:18.668480Z",
     "start_time": "2025-06-12T16:10:18.665856Z"
    }
   },
   "source": [
    "extract_fact = RunnableLambda(extract_fact)\n",
    "replace_word = RunnableLambda(replace_word)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:10:22.672986Z",
     "start_time": "2025-06-12T16:10:22.670435Z"
    }
   },
   "source": "chain = prompt | llm | output_parser | extract_fact | replace_word",
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:10:35.907836Z",
     "start_time": "2025-06-12T16:10:23.726100Z"
    }
   },
   "source": [
    "result = chain.invoke(\"AI\")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:10:38.810744Z",
     "start_time": "2025-06-12T16:10:38.808170Z"
    }
   },
   "source": [
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is Artificial Intelligence?**\n",
      "Artificial Intelligence (Josh) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and perception. Josh systems use algorithms and data to make decisions, identify patterns, and learn from experience.\n",
      "**Types of Josh:**\n",
      "1. **Narrow or Weak Josh:** Designed to perform a specific task, such as facial recognition, language translation, or playing chess.\n",
      "2. **General or Strong Josh:** A hypothetical Josh system that can perform any intellectual task that humans can, with no limitations.\n",
      "3. **Superintelligence:** An Josh system that is significantly more intelligent than the best human minds.\n",
      "**Josh Applications:**\n",
      "1. **Virtual Assistants:** Siri, Alexa, and Google Assistant use Josh to understand voice commands and respond accordingly.\n",
      "2. **Image Recognition:** Josh-powered systems like Facebook's facial recognition feature and Google Photos' image tagging allow for automatic identification of objects and people in images.\n",
      "3. **Predictive Analytics:** Josh algorithms analyze data to predict customer behavior, detect anomalies, and optimize business processes.\n",
      "4. **Robotics:** Josh-controlled robots can perform tasks such as assembly, maintenance, and healthcare.\n",
      "**Challenges and Concerns:**\n",
      "1. **Job Displacement:** As Josh takes over routine tasks, there is a risk of job displacement for certain professions.\n",
      "2. **Bias and Fairness:** Josh systems can perpetuate biases if trained on biased data or designed with flawed algorithms.\n",
      "3. **Security Risks:** Josh-powered systems can be vulnerable to cyber attacks and data breaches.\n",
      "**Future of Josh:**\n",
      "1. **Increased Adoption:** Josh is expected to become more widespread in industries such as healthcare, finance, and transportation.\n",
      "2. **Advancements in Natural Language Processing (NLP):** NLP will continue to improve, enabling Josh systems to understand and generate human-like language.\n",
      "3. **Ethics and Governance:** As Josh becomes more pervasive, there will be a growing need for regulations and guidelines to ensure responsible development and deployment of Josh systems.\n",
      "This report provides an overview of the current state of Artificial Intelligence, its applications, challenges, and future prospects.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
