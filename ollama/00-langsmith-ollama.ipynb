{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangSmith Starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith is an advanced open-source library tailored for AI Engineers, focusing on enabling seamless development and deployment of language-based AI systems. With an emphasis on modularity and interoperability, LangSmith simplifies the integration of natural language processing (NLP) capabilities into AI workflows, offering intuitive tools for fine-tuning, optimization, and interaction. It empowers developers to switch effortlessly between language models, customize pipelines, and deploy scalable, production-ready applications with minimal friction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super important note, you need to run LangSmith on more then 0.1.45 and be using the current API keys and not the legacy keys, if you do not do this you will recieve a 401 error message saying the token you are using is invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This below is the enviroment data for enabling tracing, very important that you do not mess around with this as even replacing a singular character can break and then you will not be able to trace anything."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:07.558547Z",
     "start_time": "2025-06-12T09:01:07.548278Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will be using OpenAI, however this is basically the exact same for llama just with a few changes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:10.499189Z",
     "start_time": "2025-06-12T09:01:10.004602Z"
    }
   },
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"qwen:0.5b\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langsmith by default will trace all the usual langchain based LLM calls, which in the tutorials case is super useful as we won't have to edit much code to get traces working."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:11.715299Z",
     "start_time": "2025-06-12T09:01:11.542304Z"
    }
   },
   "source": [
    "llm.invoke(\"hello\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen:0.5b', 'created_at': '2025-06-12T09:01:11.711909Z', 'done': True, 'done_reason': 'stop', 'total_duration': 165009000, 'load_duration': 39841100, 'prompt_eval_count': 9, 'prompt_eval_duration': 34181400, 'eval_count': 10, 'eval_duration': 90110100, 'model_name': 'qwen:0.5b'}, id='run--73b4fddb-c1ab-44e5-9791-c6001a99f19e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is settup for the non-langchain function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:12.360212Z",
     "start_time": "2025-06-12T09:01:12.357381Z"
    }
   },
   "source": [
    "import ollama\n",
    "\n",
    "client = ollama"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use a non langchain related function, and these are not automatically traced by langsmith, so instead, we have to add the traceable decorator."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:13.158082Z",
     "start_time": "2025-06-12T09:01:13.154917Z"
    }
   },
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable\n",
    "def generate_response(question: str):\n",
    "\n",
    "    complete_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a happy assistant\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    return client.chat(\n",
    "        model = model_name,\n",
    "        messages = complete_messages,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:14.250653Z",
     "start_time": "2025-06-12T09:01:13.583540Z"
    }
   },
   "source": [
    "generate_response(\"How are you today?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='qwen:0.5b', created_at='2025-06-12T09:01:14.2455124Z', done=True, done_reason='stop', total_duration=656486800, load_duration=44848800, prompt_eval_count=22, prompt_eval_duration=61308000, eval_count=56, eval_duration=549048200, message=Message(role='assistant', content=\"As an AI language model, I don't have emotions or feelings of happiness. However, I am constantly learning and improving my abilities to assist users in various ways. So, while I don't experience happiness, I am always working towards providing the best possible assistance to users.\", thinking=None, images=None, tool_calls=None))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add data into the traceable by editing its paramaters, this includes metadata, and what we will change, the function name."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:14.369040Z",
     "start_time": "2025-06-12T09:01:14.364415Z"
    }
   },
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"Qwen Response\")\n",
    "def generate_second_response(question: str):\n",
    "\n",
    "    complete_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a happy assistant\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    return client.chat(\n",
    "        model = model_name,\n",
    "        messages = complete_messages,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T09:01:15.674874Z",
     "start_time": "2025-06-12T09:01:15.155781Z"
    }
   },
   "source": [
    "generate_second_response(\"How are you today?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='qwen:0.5b', created_at='2025-06-12T09:01:15.6714499Z', done=True, done_reason='stop', total_duration=508944800, load_duration=38948800, prompt_eval_count=22, prompt_eval_duration=22289000, eval_count=40, eval_duration=444729900, message=Message(role='assistant', content=\"As an AI language model, I don't have feelings or emotions. However, I am always ready and ready to assist you in any way possible. So, how can I help you today?\", thinking=None, images=None, tool_calls=None))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can view all of this over at the LangSmith website, under the tracing projects."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
